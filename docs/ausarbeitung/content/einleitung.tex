%!TEX root = ../ausarbeitung.tex
\newpage
\section{Einleitung}

Kamerafallen bieten eine immer wichtiger werdende Möglichkeiten Populationen zu überwachen und erforschen. Forschungsinteressen sind beispielsweise die Veränderung der Biodiversität, der Einfluss des Klimawandels und anderer Einflüsse auf die Lebensräume und die Migrationsmuster von Populationen.

Durch die immer größer werdende Akzeptanz von Kamerafallen, steigende Qualität und sinkende Preise kommt es zu einer exponentiell wachsenden Datenmenge. Diesen Daten manuell Herr zu werden stellt eine Herausforderung dar und aufgrund der Verwendung von unveröffentlichten Daten in aktuellen Forschungsvorhaben ist Crowd-Sourcing oft unmöglich. Die anfallenden Bilder zeichnen sich durch einen hohen Anteil von False-Positives und eine große Vielfalt von Arten in verschiedensten Posen, Entfernungen und bei wechselnden Witterungsbedingungen aus. 

Im Kontext dieser Arbeit beziehen wir uns dabei auf einen Datensatz aus dem niederländischen Nationalpark \enquote{Hoge Veluwe}. Die Datenbank umfasst 40 GB Bilder von neun einheimischen Tierspezies, die mithilfe von RECONYX-Kamerafallen gesammelt wurden. Dabei wurden sowohl Farbbilder am Tag als auch Infrarotbilder in der Nacht geschossen.

Um diese komplexe Aufgabe zu automatisieren, stellen wir eine Softwarepipeline vor, mit deren Hilfe es möglich ist alle nacheinander anfallenden Herausforderungen zu lösen. Der erste Schritt besteht in der Ordnung der Daten. Dafür haben wir mit dem \emph{Camera Trap Sequencer} eine Software mit grafischer Benutzeroberfläche implementiert, die es dem Benutzer erlaubt nach Tierarten vorsortierte Datenbanken oder einzelne Ordner von Bildern auf zusammenhängende Sequenzen aufzuteilen.

Der nächste Schritt ist die Lokalisierung von Tierarten in Bildern. Das ermöglicht zum einen das Aussortieren von Bildern, die in Wirklichkeit keine Tiere zeigen, und zum anderen die Identifikation von Bildausschnitten, die für die spätere Klassifizierung relevant sind. Hierfür verwenden wir eine Pipeline mit verschiedenen Vor- und Nachbereitungsschritten, die mithilfe von \emph{Principal Components Analysis} ein Hintergrundbild auf einer Bildsequenz berechnet und somit die Segmentierung von relevanten Bildausschnitten erlaubt. Um auch die Lokalisierung von Tieren auf Einzelbildern zu erlauben, wurde zusätzlich ein PCA-unterstütztes \emph{Sliding-Window-Verfahren} implementiert. 

Den Abschluss jeder Auswertung bildet das Klassifizieren von Spezies in zuvor bestimmten \emph{Regions of Interest}. Hierzu stellen wir zwei verschiedene Techniken vor:
Die erste ist die Klassifizierung mit Hilfe einer \emph{Support Vector Machine} mit \emph{Radial-Basis-Function}-Kernel auf dem \emph{Histogram-of-oriented-Gradients}-Feature, einem Strukturfeature. 
Das zweite Verfahren ist \emph{Spatial Pyramid Matching} (SPM) mit \emph{Locality-constrained linear Coding}. Hierbei wird das Eingabebild in immer feinere Teilbilder unterteilt, auf denen dann SIFT oder LBP Features berechnet werden. Diese Features werden mit LLC kodiert, wobei die räumliche Aufteilung erhalten bleibt. Abschließend werden die so bestimmtem Codes zum Trainieren einer Support Vector Machine mit linearem Kernel benutzt, da sich empirisch erwiesen hat, dass sie gut linear separierbar sind . 

Zum Abschluss unserer Ausarbeitung evaluieren wir unsere Verfahren. Betrachtet werden sowohl die Laufzeit der Algorithmen als auch ihre Güte auf den uns zur Verfügung stehenden Daten. Da der ursprüngliche Datensatz zu groß ist, betrachten wir dabei lediglich zwei repräsentative Teilmengen:
In der DDD befinden sich Tagbilder von Dachsen und Damhirschen. Die geringe Datenmenge erlaubte schnelle Ergebnisse, ohne grundlegende Probleme, wie beispielsweise unterschiedlich unbalancierte Klassenhäufigkeiten, aus dem Blick zu verlieren.
Für die DDD+ haben wir über 2000 Tag- und Nachtbilder von insgesamt sechs verschiedenen Tierarten zusammengestellt. Ziel ist hierbei die Bestimmung der Güte des Verfahrens auf einem komplexen Datensatz.
